# 本地文档递归翻译任务

这个任务是我对DeepWiki抓取和本地化处理的后续工作，虽然直接读英语也毕竟不是不行，但不是母语的话就做不到“一目十行”的效果，阅读速度太慢。

所以我写了以下Prompt，用来指导本地AI Agents对本地文档进行递归翻译工作。

<details>  
<summary>Click to expand</summary>

```md
{% include "./文档翻译.md" %}
```
</details>

然后我切换到[Docker Docs](https://github.com/docker/docs)文档仓库，启动[Copilot API](https://github.com/ericc-ch/copilot-api)，将copilot反代给claude-code使用，并行开了4个窗口，每个窗口一个文件夹。我选择了最好的3x速率模型Claude Opus 4.5(3x)速率，心想以往copilot反代给cc额度消耗速率都非常慢，有时候一次对话能持续20分钟，完成很多很多任务，所以我就打算直接用最好的模型速通这个任务。

检查任务进行了一会儿，claude-code每个窗口都说要开sub-agents进行并行工作，我都同意了。不得不说cc干活就是快，眨眼间1000个文件都翻译好了我随手点开了copilot剩余额度看了一眼：

![Copilot额度](copilot剩余额度.png)

好家伙，怎么直接把300次额度全干没了？

很快，copilot反代后端就陆陆续续收到[429速率限制报错](https://docs.github.com/en/copilot/how-tos/troubleshoot-copilot/troubleshoot-common-issues#error-sorry-your-request-was-rate-limited)，连免费模型都用不了了：

![alt text](image.png)

我这才意识到sub-agents额度消耗的恐怖性：每个子代理都会消耗一次请求，cc开了数十个代理，所以额度会瞬间清空。

好吧，这下用不了cc了，那就换gemini吧。免费的gemini肯定不如cc好用：

1. gemini在vscode的Terminal下容易卡死
2. gemini不支持sub-agents，翻译速度慢
3. 翻译水平和代码水平大概率不如claude-code

而且我想半夜跑翻译任务，所以我就在我的macmini上打开了gemini-cli。不得不说gemini-cli在mac的iTerm2下运行非常稳定，没有卡死，但是偶有闪屏情况。

gemini不支持sub-agents，翻译速度就会慢很多，而且出现了3个文件夹翻译完之后只剩最后一个文件夹的情况，那么整个任务的进度就会被最慢的文件夹拖住。如果想提速，可能又要对该文件夹进行任务划分和手动并行，这已经可以提取出一套工作流进行后续复用了，毕竟这种极为简单却繁琐的翻译任务由人来盯着进度实在是太浪费时间了。直到这时我才明白github上一些对cc进行“监工”，强迫claude-code一直持续工作的项目意义了。

Vibe-coding时代，可复用的工作流依然是有意义并且值得去思考如何优化的。
